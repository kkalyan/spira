# Example configuration for Spira - Intelligent SQL generation system

# Notebook source - where your Jupyter/Zeppelin notebooks are stored
notebook_source: "s3://my-data-bucket/notebooks/"  # or "/local/path/to/notebooks"

# AWS Glue Catalog configuration for table metadata
glue_catalog:
  account_id: "123456789012"  # AWS account ID with the Glue catalog
  region: "us-east-1"
  
  # Option 1: Specify databases to include
  databases: 
    - "sales_db"
    - "customer_db" 
    - "product_db"
  
  # Option 2: Specify specific tables (alternative to databases)
  # tables:
  #   - "sales_db.transactions"
  #   - "sales_db.customers"
  #   - "product_db.catalog"
  
  # For cross-account access (optional)
  # cross_account_role_arn: "arn:aws:iam::OTHER-ACCOUNT-ID:role/CrossAccountGlueRole"

# AWS OpenSearch configuration
opensearch:
  endpoint: "my-opensearch-domain.us-east-1.es.amazonaws.com"
  region: "us-east-1"
  index_name: "spira-knowledge"
  use_ssl: true
  verify_certs: true

# AWS Bedrock model configuration
models:
  # Fast model for offline processing (parsing notebooks, analysis)
  offline_model: "anthropic.claude-3-haiku-20240307-v1:0"
  
  # Best model for online SQL generation
  online_model: "anthropic.claude-3-5-sonnet-20241022-v2:0"
  
  # Embedding model for vector search
  embedding_model: "amazon.titan-embed-text-v2:0"
  
  # AWS region for Bedrock services
  region: "us-east-1"

# Processing configuration (optional - these are defaults)
processing:
  max_workers: 10              # Parallel workers for processing
  batch_size: 100             # Batch size for OpenSearch operations
  chunk_size: 1000            # Text chunk size for embeddings
  similarity_threshold: 0.7    # Minimum similarity score for citations